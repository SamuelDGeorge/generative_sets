{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#general\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#for utility packages\n",
    "from Utilities.utilities import import_data\n",
    "from Utilities.utilities import reset_graph\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tan.tan_util import get_tan_nll as tan\n",
    "from tan.tan_util import get_tan_nll_cond as tan_cond\n",
    "\n",
    "from tensorflow.contrib.slim.nets import resnet_v2\n",
    "import imagenet_helper_files.vgg_preprocessing\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "#For parsing records once written\n",
    "from Utilities.set_record_parser import build_set_dataset\n",
    "from Utilities.set_record_parser import get_file_lists\n",
    "from Utilities.models import log_dir_build\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Directories \n",
    "\n",
    "Here we are going to get the files needed to do the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate Neccesary Files\n",
    "homogenous_train = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Original_Images_Train.pkl\", \"rb\")\n",
    "nonhomogenous_train = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Inhomogeneous_Images_Train.pkl\", \"rb\")\n",
    "homogenous_test = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Original_Images_Test.pkl\", \"rb\")\n",
    "nonhomogenous_test = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Inhomogeneous_Images_Test.pkl\", \"rb\")\n",
    "train_homog = pickle.load(homogenous_train)\n",
    "train_homog_labels = np.zeros(train_homog.shape[0])\n",
    "train_nonhomog = pickle.load(nonhomogenous_train)\n",
    "train_nonhomog_labels = np.ones(train_homog.shape[0])\n",
    "test_homog = pickle.load(homogenous_test)\n",
    "test_homog_labels = np.zeros(test_homog.shape[0])\n",
    "test_nonhomog = pickle.load(nonhomogenous_test)\n",
    "test_nonhomog_labels = np.ones(test_homog.shape[0])\n",
    "homogenous_train.close()\n",
    "nonhomogenous_train.close()\n",
    "homogenous_test.close()\n",
    "nonhomogenous_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine into full train and test set as well as ground truth\n",
    "full_train = np.expand_dims(np.concatenate((train_homog, train_nonhomog), axis = 0), axis=4)\n",
    "full_train_labels = np.concatenate((train_homog_labels, train_nonhomog_labels), axis=0)\n",
    "\n",
    "full_test = np.expand_dims(np.concatenate((test_homog, test_nonhomog), axis = 0), axis=4)\n",
    "full_test_labels = np.concatenate((test_homog_labels, test_nonhomog_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_1 = full_test[0]\n",
    "full_test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Neural Network\n",
    "\n",
    "The following provides the code to import and use the TF_Records for the set project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory for logs in training\n",
    "set_net_logs = 'D:/AI/models/set_project_brain/logs'\n",
    "model_path = log_dir_build(set_net_logs, \"set_project_brain\")\n",
    "#model_path = 'D:/AI/models/set_project_brain/logs/set_project-run-20190306174848/'\n",
    "\n",
    "#directory for all the models saved during training\n",
    "set_net_model = 'D:/AI/models/set_project_brain/model/' + 'set_project'\n",
    "set_net_model_best = 'D:/AI/models/set_project_brain/model/' + 'set_project_best'\n",
    "res_net_model = \"D:/AI/models/res_net/v2_50/resnet_v2_50.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_set_layer(input_code, input_size, condense_size, set_size=3, layer_name='default', activation_func=tf.nn.sigmoid):\n",
    "    \n",
    "    learned_transform = tf.get_variable(layer_name + '_transform', shape=[input_size,condense_size], \n",
    "                                        trainable=True, initializer=tf.contrib.layers.variance_scaling_initializer()) \n",
    "    batched_transform = tf.broadcast_to(learned_transform, [tf.shape(input_code)[0], input_size, condense_size])\n",
    "    transform_layer = tf.matmul(input_code, batched_transform)\n",
    "    activation = activation_func(transform_layer)\n",
    "    \n",
    "    \n",
    "    lambda_1 = tf.get_variable(layer_name + \"_lambda\", [condense_size], trainable=True, dtype=tf.float32, initializer=tf.initializers.random_normal(mean=1))\n",
    "    lambda_1_transformed = tf.broadcast_to(lambda_1, [set_size, condense_size])\n",
    "    multipy_pairwise = tf.broadcast_to(lambda_1_transformed, [tf.shape(input_code)[0], set_size, condense_size])\n",
    "    \n",
    "    sigma_1 = tf.abs(tf.get_variable(layer_name + \"_sigma\", [condense_size], trainable=True, dtype=tf.float32, initializer=tf.initializers.random_normal(mean=0)))\n",
    "    sigma_1_tranformed = tf.broadcast_to(sigma_1, [tf.shape(input_code)[0], condense_size])\n",
    "    \n",
    "\n",
    "    # + sigma * mean(Data)\n",
    "    max_pool_1 = tf.reduce_mean(activation, axis=1)\n",
    "    sum_term = tf.multiply(sigma_1_tranformed, max_pool_1)\n",
    "    sum_term_final = tf.expand_dims(sum_term, axis=1)  \n",
    "    \n",
    "    pre_activation_1 = tf.multiply(activation, multipy_pairwise) + sum_term_final\n",
    "    layer_1 = activation_func(pre_activation_1)\n",
    "    return layer_1\n",
    "\n",
    "def pad_and_input(original_image):\n",
    "    new_image = tf.image.resize_image_with_crop_or_pad(original_image, 331,331)\n",
    "    new_image = tf.image.grayscale_to_rgb(new_image)\n",
    "    return new_image\n",
    "\n",
    "def resnet_build(input):\n",
    "    input = pad_and_input(input)\n",
    "    net, end_points = resnet_v2.resnet_v2_50(input, is_training=False)\n",
    "    saver = tf.train.Saver(name=\"Original_Saver\")\n",
    "    return(net, end_points, saver)\n",
    "\n",
    "def get_resnet_estimate(item):\n",
    "    item = pad_and_input(item)\n",
    "    net, end_points = resnet_v2.resnet_v2_50(item, reuse=True,is_training=False)\n",
    "    net = tf.layers.flatten(net)\n",
    "    return(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"StopGradient:0\", shape=(?, 3, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "#Placeholder for choosing input, epochs, batches, and datasets at runtime\n",
    "learning_rate_class = .01\n",
    "dropout_rate = 0.2\n",
    "set_size = 3\n",
    "    \n",
    "with tf.name_scope('Data_Retrieval'):\n",
    "    #put the data in the graph\n",
    "    batch_size = tf.placeholder_with_default(30, shape=[], name= \"Batch_Size\")\n",
    "    training = tf.placeholder_with_default(True, shape=(), name = 'training')\n",
    "    data_set = tf.placeholder(shape=[None,set_size,128,128,1], name=\"All_Data\", dtype=tf.float32)\n",
    "    image_set = tf.placeholder(shape=[None,set_size,331,331,3], name=\"All_Data\", dtype=tf.float32)\n",
    "    data_label = tf.placeholder(shape=[None], name=\"Data_Labels\", dtype=tf.int32)  \n",
    "    data_sample = tf.placeholder(shape=[set_size,128,128,1], name=\"All_Data_sample\", dtype=tf.float32)\n",
    "    image_sample = tf.placeholder(shape=[set_size,331,331,3], name=\"All_Data_sample\", dtype=tf.float32)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"BN_Layer_AE_Layers\"):\n",
    "    #Define initalizer and batch normalization layers\n",
    "    bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "    final_net_output, end_point, saver_resnet = resnet_build(data_sample)\n",
    "    encoding_raw = tf.map_fn(lambda x: get_resnet_estimate(x), data_set, dtype=(tf.float32))\n",
    "    encoding = tf.stop_gradient(encoding_raw)\n",
    "print(encoding)\n",
    "\n",
    "with tf.name_scope(\"Set_Analyzer\"):\n",
    "    #the network for generating output of our set\n",
    "    with tf.name_scope('Unique_Identify'):\n",
    "        code_size = 2048\n",
    "        n_layer_1 = 1000\n",
    "        n_layer_2 = 500\n",
    "        n_layer_3 = 250\n",
    "        n_unq_1 = 100\n",
    "        n_unq_2 = 10\n",
    "        n_unq_final = 2\n",
    "        deep_activation = tf.nn.relu\n",
    "        \n",
    "        batch_item = batch_size\n",
    "        \n",
    "        with tf.name_scope('DeepSet_Layer_1'):\n",
    "            #1000\n",
    "            deep_1 = deep_set_layer(encoding, code_size, n_layer_1, set_size=3, layer_name='Deep_One', activation_func=deep_activation)\n",
    "        \n",
    "        with tf.name_scope('DeepSet_Unq_Layer_1'):\n",
    "            #500 Output\n",
    "            deep_unq_1 = deep_set_layer(deep_1, n_layer_1, n_layer_2, set_size=3, layer_name='Deep_Unq_One', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('DeepSet_Unq_Layer_2'):\n",
    "            #250 Output\n",
    "            deep_unq_2 = deep_set_layer(deep_unq_1, n_layer_2, n_layer_3, set_size=3, layer_name='Deep_Unq_Two', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('Final_Unq_Deep_Pool'):\n",
    "            #250 Output\n",
    "            final_unq_deep_layer = tf.reduce_sum(deep_unq_2, 1)\n",
    "            \n",
    "        with tf.name_scope(\"Unq_Hidden_Layer_1\"):\n",
    "            #100 Output\n",
    "            hidden1_unq = tf.layers.dense(final_unq_deep_layer, n_unq_1, name=\"hidden1_unq\", kernel_initializer=he_init)\n",
    "            hidden1_drop_unq = tf.layers.dropout(hidden1_unq, dropout_rate, training=training)\n",
    "            hidden1_cast_unq = tf.cast(hidden1_drop_unq, tf.float32)\n",
    "            bn1_cat_unq = bn_batch_norm_layer(hidden1_cast_unq)\n",
    "            bn1_act_cat_unq = tf.nn.relu(bn1_cat_unq)  \n",
    "            \n",
    "        with tf.name_scope(\"Unq_Hidden_Layer_2\"):\n",
    "            #10 Output\n",
    "            hidden2_unq = tf.layers.dense(bn1_act_cat_unq, n_unq_2, name=\"hidden2_unq\", kernel_initializer=he_init)\n",
    "            hidden2_drop_unq = tf.layers.dropout(hidden2_unq, dropout_rate, training=training)\n",
    "            bn2_cat_unq = bn_batch_norm_layer(hidden2_drop_unq)\n",
    "            bn2_act_cat_unq = tf.nn.relu(bn2_cat_unq)  \n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"Final_Layer_unq\"): \n",
    "            #Get softmax\n",
    "            logits_before_bn_unq = tf.layers.dense(bn2_act_cat_unq, n_unq_final, name=\"outputs_unq\")\n",
    "            logits_unq = bn_batch_norm_layer(logits_before_bn_unq, name=\"logits_unq\")\n",
    "            softmax_unq = tf.nn.softmax(logits_unq, name=\"final_soft_max_unq\")\n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"Unique_loss\"):           \n",
    "            \n",
    "            #Get cross entropy from labels\n",
    "            xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=data_label, logits=logits_unq)\n",
    "            loss_unq = tf.reduce_mean(xentropy, name=\"loss_unq\")\n",
    "            loss_summary_unq = tf.summary.scalar('loss_summary_unq', loss_unq)\n",
    "            \n",
    "        with tf.name_scope(\"eval_unq\"):\n",
    "            correct = tf.nn.in_top_k(logits_unq, data_label, 1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "            accuracy_summary = tf.summary.scalar('accuracy_summary', accuracy)\n",
    "                \n",
    "        with tf.name_scope(\"unique_train\"):\n",
    "            global_step_unique = tf.Variable(0, trainable=False, name='global_step_unique')\n",
    "            optimizer_unq = tf.train.AdamOptimizer(learning_rate=learning_rate_class)\n",
    "\n",
    "            extra_update_ops_unq = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(extra_update_ops_unq):\n",
    "                 training_op_unq = optimizer_unq.minimize(loss_unq, global_step=global_step_unique)\n",
    "\n",
    "init = tf.global_variables_initializer()    \n",
    "saver_total = tf.train.Saver(name=\"Full_Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Graph to log directory\n",
    "filewriter = tf.summary.FileWriter(model_path, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26222216\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/AI/models/res_net/v2_50/resnet_v2_50.ckpt\n"
     ]
    }
   ],
   "source": [
    "#Initialize the network\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver_resnet.restore(sess,res_net_model)\n",
    "    saver_total.save(sess, set_net_model)\n",
    "    saver_total.save(sess, set_net_model_best)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/AI/models/set_project_brain/logs/set_project_brain-run-20190421195537/\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network\n",
    "\n",
    "Train the network to both generate conditioning for the network and also classify the type of set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/AI/models/set_project_brain/model/set_project\n",
      "Loaded model. Training network initially. Logs into: D:/AI/models/set_project_brain/logs/set_project_brain-run-20190421195537/\n",
      "Epoch: 1 Unique Loss: 11.833126\n",
      "Epoch: 2 Unique Loss: 3.4355102\n",
      "Epoch: 3 Unique Loss: 0.95235795\n",
      "Epoch: 4 Unique Loss: 0.85966694\n",
      "Epoch: 5 Unique Loss: 0.6923218\n",
      "Epoch: 6 Unique Loss: 0.68340325\n",
      "Epoch: 7 Unique Loss: 0.7552413\n",
      "Epoch: 8 Unique Loss: 0.70233727\n",
      "Epoch: 9 Unique Loss: 0.7915849\n",
      "Epoch: 10 Unique Loss: 0.6211464\n",
      "Epoch: 11 Unique Loss: 0.81173617\n",
      "Epoch: 12 Unique Loss: 0.74673975\n",
      "Epoch: 13 Unique Loss: 0.7042749\n",
      "Epoch: 14 Unique Loss: 0.6732344\n",
      "Epoch: 15 Unique Loss: 0.6987769\n",
      "Epoch: 16 Unique Loss: 0.698826\n",
      "Epoch: 17 Unique Loss: 0.73891425\n",
      "Epoch: 18 Unique Loss: 0.76117384\n",
      "Epoch: 19 Unique Loss: 0.64462864\n",
      "Epoch: 20 Unique Loss: 0.7443029\n",
      "Epoch: 21 Unique Loss: 0.67814845\n",
      "Epoch: 22 Unique Loss: 0.6998426\n",
      "Epoch: 23 Unique Loss: 0.69202983\n",
      "Epoch: 24 Unique Loss: 0.702614\n",
      "Epoch: 25 Unique Loss: 0.7049734\n",
      "Epoch: 26 Unique Loss: 0.6887373\n",
      "Epoch: 27 Unique Loss: 0.69927585\n",
      "Epoch: 28 Unique Loss: 0.69053465\n",
      "Epoch: 29 Unique Loss: 0.6907848\n",
      "Epoch: 30 Unique Loss: 0.69754726\n",
      "Epoch: 31 Unique Loss: 0.6908056\n",
      "Epoch: 32 Unique Loss: 0.6863679\n",
      "Epoch: 33 Unique Loss: 0.6798925\n",
      "Epoch: 34 Unique Loss: 0.6175842\n",
      "Epoch: 35 Unique Loss: 0.77258986\n",
      "Epoch: 36 Unique Loss: 0.72766346\n",
      "Epoch: 37 Unique Loss: 0.73755586\n",
      "Epoch: 38 Unique Loss: 0.7053522\n",
      "Epoch: 39 Unique Loss: 0.692974\n",
      "Epoch: 40 Unique Loss: 0.6936252\n",
      "Epoch: 41 Unique Loss: 0.716426\n",
      "Epoch: 42 Unique Loss: 0.6745977\n",
      "Epoch: 43 Unique Loss: 0.7402936\n",
      "Epoch: 44 Unique Loss: 0.6911676\n",
      "Epoch: 45 Unique Loss: 0.6974787\n",
      "Epoch: 46 Unique Loss: 0.7088329\n",
      "Epoch: 47 Unique Loss: 0.6836196\n",
      "Epoch: 48 Unique Loss: 0.6905735\n",
      "Epoch: 49 Unique Loss: 0.6948005\n",
      "Epoch: 50 Unique Loss: 0.7003526\n",
      "Epoch: 51 Unique Loss: 0.64226735\n",
      "Epoch: 52 Unique Loss: 0.6938651\n",
      "Epoch: 53 Unique Loss: 0.6788082\n",
      "Epoch: 54 Unique Loss: 0.68019146\n",
      "Epoch: 55 Unique Loss: 0.70046717\n",
      "Epoch: 56 Unique Loss: 0.6883897\n",
      "Epoch: 57 Unique Loss: 0.6913522\n",
      "Epoch: 58 Unique Loss: 0.73994005\n",
      "Epoch: 59 Unique Loss: 0.6955241\n",
      "Epoch: 60 Unique Loss: 0.76382315\n",
      "Epoch: 61 Unique Loss: 0.6617049\n",
      "Epoch: 62 Unique Loss: 0.6765651\n",
      "Epoch: 63 Unique Loss: 0.6821838\n",
      "Epoch: 64 Unique Loss: 0.6903891\n",
      "Epoch: 65 Unique Loss: 0.70681113\n",
      "Epoch: 66 Unique Loss: 0.6923386\n",
      "Epoch: 67 Unique Loss: 0.6910798\n",
      "Epoch: 68 Unique Loss: 0.6927224\n",
      "Epoch: 69 Unique Loss: 0.6939382\n",
      "Epoch: 70 Unique Loss: 0.6914104\n",
      "Epoch: 71 Unique Loss: 0.69388187\n",
      "Epoch: 72 Unique Loss: 0.68477845\n",
      "Epoch: 73 Unique Loss: 0.69115865\n",
      "Epoch: 74 Unique Loss: 0.70585936\n",
      "Epoch: 75 Unique Loss: 0.6923874\n",
      "Epoch: 76 Unique Loss: 0.6950171\n",
      "Epoch: 77 Unique Loss: 0.68952584\n",
      "Epoch: 78 Unique Loss: 0.6911678\n",
      "Epoch: 79 Unique Loss: 0.6852869\n",
      "Epoch: 80 Unique Loss: 0.69822466\n",
      "Epoch: 81 Unique Loss: 0.693558\n",
      "Epoch: 82 Unique Loss: 0.6980372\n",
      "Epoch: 83 Unique Loss: 0.70443237\n",
      "Epoch: 84 Unique Loss: 0.69001794\n",
      "Epoch: 85 Unique Loss: 0.68952066\n",
      "Epoch: 86 Unique Loss: 0.6896216\n",
      "Epoch: 87 Unique Loss: 0.69646835\n",
      "Epoch: 88 Unique Loss: 0.6687027\n",
      "Epoch: 89 Unique Loss: 0.7151056\n",
      "Epoch: 90 Unique Loss: 0.6907561\n",
      "Epoch: 91 Unique Loss: 0.73171484\n",
      "Epoch: 92 Unique Loss: 0.70973456\n",
      "Epoch: 93 Unique Loss: 0.71241134\n",
      "Epoch: 94 Unique Loss: 0.69041\n",
      "Epoch: 95 Unique Loss: 0.68929577\n",
      "Epoch: 96 Unique Loss: 0.7021246\n",
      "Epoch: 97 Unique Loss: 0.6868773\n",
      "Epoch: 98 Unique Loss: 0.6865417\n",
      "Epoch: 99 Unique Loss: 0.6931541\n",
      "Epoch: 100 Unique Loss: 0.7019712\n",
      "Epoch: 101 Unique Loss: 0.6986866\n",
      "Epoch: 102 Unique Loss: 0.6894906\n",
      "Epoch: 103 Unique Loss: 0.6765836\n",
      "Epoch: 104 Unique Loss: 0.7594903\n",
      "Epoch: 105 Unique Loss: 0.716542\n",
      "Epoch: 106 Unique Loss: 0.77552384\n",
      "Epoch: 107 Unique Loss: 0.67710245\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5afe62ff37b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m#run Training Op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_op_unq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_label\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_train_label\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m#see if we are improving on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "steps_between_test_save = 1\n",
    "batch = 15\n",
    "train_size = 600\n",
    "#all_data_steps = np.int(np.floor(train_size/batch))\n",
    "all_data_steps = 2\n",
    "worst_acc = 0\n",
    "\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    #restore saver, build iterator, set the step to the global step\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    \n",
    "    #Set up the global steps\n",
    "    step = 1\n",
    "    print(\"Loaded model. Training network initially. Logs into: \" + model_path)\n",
    "    \n",
    "    #Iterate through training \n",
    "    while step < epochs:\n",
    "        for i in range(all_data_steps):\n",
    "            idx = np.random.randint(full_train.shape[0], size=batch)\n",
    "            batch_train = full_train[idx,:]\n",
    "            batch_train_label = full_train_labels[idx]\n",
    "            \n",
    "            #run Training Op\n",
    "            sess.run([training_op_unq], feed_dict={data_set: batch_train, data_label: batch_train_label})\n",
    "        \n",
    "        #see if we are improving on the test data\n",
    "        #Maybe Test Accuracy\n",
    "        if ((step % steps_between_test_save) == 0) :\n",
    "            idx = np.random.randint(full_test.shape[0], size=batch)\n",
    "            batch_test = full_test[idx,:]\n",
    "            batch_test_label = full_test_labels[idx]\n",
    "            \n",
    "            loss_un, loss_un_val, acc, acc_sum = sess.run([loss_summary_unq, loss_unq, accuracy, accuracy_summary], \n",
    "                                                   feed_dict = {data_set: batch_test , data_label: batch_test_label, training: False, batch_size: batch})\n",
    "\n",
    "            filewriter.add_summary(loss_un, step)\n",
    "            filewriter.add_summary(acc_sum, step)\n",
    "            print(\"Epoch: \" + str(step) + \" Unique Loss: \" + str(loss_un_val) + \" Accuracy: \" + str(acc))\n",
    "            if acc > worst_acc:\n",
    "                saver_total.save(sess, set_net_model_best)\n",
    "                worst_acc = acc\n",
    "            saver_total.save(sess, set_net_model)\n",
    "        step = step + 1\n",
    "            \n",
    "    #Finish the final Model\n",
    "    saver_total.save(sess, set_net_model)\n",
    "    end_time = time.time()\n",
    "    total_steps = tf.train.global_step(sess, global_step_unique)\n",
    "    final_time = end_time - start_time\n",
    "    print(\"Did \" + str(total_steps) + \" of loss minimized training in \" + str(final_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Training\n",
    "\n",
    "Here we will see how the network performs after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 30\n",
    "epochs = 100\n",
    "num_iter = 200\n",
    "with tf.Session() as sess:\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    #initialize iterator\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: batch, num_epochs:epochs})\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "    right, guess, acc, cond, ims, cc = sess.run([correct_class, classes_guess, class_accuracy, conditionals, file_data, code_data], feed_dict={handle: val_handle, training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get final parameter count\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_code = cc[item_number]\n",
    "for i in core_code:\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(i)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_set = np.where(right[item_number] == 1)[0]\n",
    "for i in in_set:\n",
    "    print('Array_Position: ' + str(i)  + ' Class_Label: ' + label_file[i])\n",
    "right[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_set = np.where(guess[item_number] == 1)[0]\n",
    "for i in in_set:\n",
    "    print('Array_Position: ' + str(i)  + ' Class_Label: ' + label_file[i])\n",
    "guess[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond[item_number][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training Metrics\n",
    "\n",
    "Here we will get final accuracies for both tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "steps_between_test_save = 1\n",
    "batch = 30\n",
    "test_size = 26000\n",
    "all_data_steps = np.int(np.floor(test_size/batch))\n",
    "unique_accuracy = 0\n",
    "identify_accuracy = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    #restore saver, build iterator, set the step to the global step\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    \n",
    "    print(\"Loaded model. Training network initially. Logs into: \" + model_path)\n",
    "    \n",
    "    #initialize iterator\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: batch, num_epochs:epochs})\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "    for i in range(all_data_steps):\n",
    "        unq_acc, ide_acc = sess.run([accuracy, class_accuracy], feed_dict = {handle: val_handle, training: False})\n",
    "        unique_accuracy = ((i  * unique_accuracy) + unq_acc)/(i + 1)\n",
    "        identify_accuracy = ((i  * identify_accuracy) + ide_acc)/(i + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Demonstration\n",
    "\n",
    "Here we are going to show running the bones of the network and look a the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #Initialize Train and validation iterator\n",
    "    sess.run(train_iterator.initializer, feed_dict={filename: train_list, batch_size: 1, num_epochs:1})\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: 1, num_epochs:1})\n",
    "    train_handle = sess.run(train_iterator.string_handle())\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "\n",
    "    test_code, test_class, test_file, test_unique = sess.run([code, class_data, file_data, uniques], feed_dict={handle: val_handle,training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show codes from single example\n",
    "for i in range(0,3):\n",
    "    X_test = test_code[0][i]\n",
    "    x_val = X_test\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(x_val)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show class for each item in set\n",
    "for i in range(0,3):\n",
    "    X_test = test_class[0][i]\n",
    "    print('Class: ' + str(X_test) + ' Label: ' + labels[X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show what images the codes came from\n",
    "print(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show how many unitque Items are in the set\n",
    "test_unique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
