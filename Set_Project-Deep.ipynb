{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#general\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#for utility packages\n",
    "from Utilities.utilities import import_data\n",
    "from Utilities.utilities import reset_graph\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tan.tan_util import get_tan_nll as tan\n",
    "from tan.tan_util import get_tan_nll_cond as tan_cond\n",
    "\n",
    "\n",
    "#For parsing records once written\n",
    "from Utilities.set_record_parser import build_set_dataset\n",
    "from Utilities.set_record_parser import get_file_lists\n",
    "from Utilities.models import log_dir_build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Directories \n",
    "\n",
    "Here we are going to get the files needed to do the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate Neccesary Files\n",
    "#Get Imageanet Label and Record Location\n",
    "labels_file = \"D:/Machine_Learning/Datasets/ImageNet_2012/labels.txt\"\n",
    "tf_record_directory =  'D:/Machine_Learning/Datasets/Set_Project/Code_Class_TF_Records'\n",
    "\n",
    "#Make \n",
    "class_file = open(labels_file,'r')\n",
    "label_file = class_file.read().split('\\n')\n",
    "class_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/Machine_Learning/Datasets/Set_Project/Code_Class_TF_Records\\\\Training_Set-00000-of-00002',\n",
       " 'D:/Machine_Learning/Datasets/Set_Project/Code_Class_TF_Records\\\\Training_Set-00001-of-00002']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import location of TF_Records\n",
    "train_list, val_list = get_file_lists(tf_record_directory)\n",
    "train_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Neural Network\n",
    "\n",
    "The following provides the code to import and use the TF_Records for the set project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory for logs in training\n",
    "set_net_logs = 'D:/AI/models/set_project/logs'\n",
    "#model_path = log_dir_build(set_net_logs, \"set_project\")\n",
    "model_path = 'D:/AI/models/set_project/logs/set_project-run-20190306174848/'\n",
    "\n",
    "#directory for all the models saved during training\n",
    "set_net_model = 'D:/AI/models/set_project/model/' + 'set_project'\n",
    "set_net_model_best = 'D:/AI/models/set_project/model/' + 'set_project_best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_set_layer(input_code, input_size, condense_size, set_size=3, layer_name='default', activation_func=tf.nn.sigmoid):\n",
    "    \n",
    "    learned_transform = tf.get_variable(layer_name + '_transform', shape=[input_size,condense_size], \n",
    "                                        trainable=True, initializer=tf.contrib.layers.variance_scaling_initializer()) \n",
    "    batched_transform = tf.broadcast_to(learned_transform, [tf.shape(input_code)[0], input_size, condense_size])\n",
    "    transform_layer = tf.matmul(input_code, batched_transform)\n",
    "    activation = activation_func(transform_layer)\n",
    "    \n",
    "    \n",
    "    lambda_1 = tf.get_variable(layer_name + \"_lambda\", [condense_size], trainable=True, dtype=tf.float32, initializer=tf.initializers.random_normal(mean=1))\n",
    "    lambda_1_transformed = tf.broadcast_to(lambda_1, [set_size, condense_size])\n",
    "    multipy_pairwise = tf.broadcast_to(lambda_1_transformed, [tf.shape(input_code)[0], set_size, condense_size])\n",
    "    \n",
    "    sigma_1 = tf.abs(tf.get_variable(layer_name + \"_sigma\", [condense_size], trainable=True, dtype=tf.float32, initializer=tf.initializers.random_normal(mean=0)))\n",
    "    sigma_1_tranformed = tf.broadcast_to(sigma_1, [tf.shape(input_code)[0], condense_size])\n",
    "    \n",
    "\n",
    "    # + sigma * mean(Data)\n",
    "    max_pool_1 = tf.reduce_mean(activation, axis=1)\n",
    "    sum_term = tf.multiply(sigma_1_tranformed, max_pool_1)\n",
    "    sum_term_final = tf.expand_dims(sum_term, axis=1)  \n",
    "    \n",
    "    pre_activation_1 = tf.multiply(activation, multipy_pairwise) + sum_term_final\n",
    "    layer_1 = activation_func(pre_activation_1)\n",
    "    return layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "#Placeholder for choosing input, epochs, batches, and datasets at runtime\n",
    "number_of_classes = 100\n",
    "learning_rate_class = .1\n",
    "dropout_rate = 0.2\n",
    "set_size = 3\n",
    "\n",
    "with tf.name_scope('Data_Retrieval'):\n",
    "    filename = tf.placeholder(tf.string, shape=[None], name=\"tf_records\")\n",
    "    batch_size = tf.placeholder(tf.int64, shape=[], name= \"Batch_Size\")\n",
    "    num_epochs = tf.placeholder(tf.int64, shape=[], name= \"Num_epochs\")\n",
    "    training = tf.placeholder_with_default(True, shape=(), name = 'training')\n",
    "    handle = tf.placeholder(tf.string, shape=[], name=\"Dataset\")\n",
    "    code_size = 2048\n",
    "\n",
    "    training_set = build_set_dataset(True, filename, code_size, set_size, batch_size, num_epochs, num_parallel_calls=8)\n",
    "    validation_set = build_set_dataset(False, filename, code_size, set_size, batch_size, num_epochs, num_parallel_calls=8)\n",
    "\n",
    "    train_iterator = training_set.make_initializable_iterator()\n",
    "    val_iterator = validation_set.make_initializable_iterator()\n",
    "\n",
    "    iterator = tf.data.Iterator.from_string_handle(\n",
    "        handle, training_set.output_types, training_set.output_shapes)\n",
    "    next_element = iterator.get_next()\n",
    "    code_data, class_data, file_data, uniques_data = next_element\n",
    "\n",
    "    code = tf.placeholder_with_default(code_data, [None,3,2048])\n",
    "    uniques = tf.placeholder_with_default(uniques_data, [None])\n",
    "\n",
    "with tf.name_scope(\"BN_Layer_AE_Layers\"):\n",
    "    #Define initalizer and batch normalization layers\n",
    "    bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "with tf.name_scope(\"Set_Analyzer\"):\n",
    "    #the network for generating output of our set\n",
    "    code_size = 2048\n",
    "    n_layer_1 = 1000\n",
    "    n_layer_2 = 500\n",
    "    n_layer_3 = 250\n",
    "    n_final_layer = 100\n",
    "    deep_activation = tf.nn.relu\n",
    "    \n",
    "    \n",
    "    with tf.name_scope('Deep_Sets'):\n",
    "        batch_item = tf.cast(batch_size, tf.int32)\n",
    "        input_before = tf.cast(code, tf.float32)\n",
    "        \n",
    "        with tf.name_scope('DeepSet_Layer_1'):\n",
    "            #1000\n",
    "            deep_1 = deep_set_layer(input_before, code_size, n_layer_1, set_size=3, layer_name='Deep_One', activation_func=deep_activation)\n",
    "\n",
    "        with tf.name_scope('DeepSet_Layer_2'):\n",
    "            #500\n",
    "            deep_2 = deep_set_layer(deep_1, n_layer_1, n_layer_2, set_size=3, layer_name='Deep_Two', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('DeepSet_Layer_3'):\n",
    "            #250\n",
    "            deep_3 = deep_set_layer(deep_2, n_layer_2, n_layer_3, set_size=3, layer_name='Deep_Three', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('Final_Deep_Pool'):\n",
    "            #250\n",
    "            final_deep_layer = tf.reduce_sum(deep_3, 1)\n",
    "            \n",
    "            \n",
    "    with tf.name_scope('Dense_Layers_Classification'):      \n",
    "        \n",
    "        with tf.name_scope(\"Class_Hidden_Layer_1\"):\n",
    "            #100\n",
    "            hidden1_cat = tf.layers.dense(final_deep_layer, n_final_layer, name=\"hidden1_cat\", kernel_initializer=he_init)\n",
    "            hidden1_drop = tf.layers.dropout(hidden1_cat, dropout_rate, training=training)\n",
    "            hidden1_cast = tf.cast(hidden1_drop, tf.float32)\n",
    "            bn1_cat = bn_batch_norm_layer(hidden1_cast)\n",
    "            bn1_act_cat = tf.nn.relu(bn1_cat)  \n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"Final_Layer\"): \n",
    "            #100\n",
    "            logits_before_bn = tf.layers.dense(bn1_act_cat, n_final_layer, name=\"outputs\")\n",
    "            logits = bn_batch_norm_layer(logits_before_bn, name=\"logits\")\n",
    "            conditionals = tf.nn.sigmoid(logits, name=\"Conditionals\")\n",
    "            softmax = tf.nn.tanh(tf.nn.relu(logits))\n",
    "            classes_guess = tf.round(softmax, name='Class_Guess')\n",
    "            \n",
    "        with tf.name_scope(\"loss\"):\n",
    "                cast_class = tf.cast(class_data, tf.int32)\n",
    "                one_hot = tf.one_hot(cast_class, number_of_classes)\n",
    "                summed_hot = tf.reduce_sum(one_hot, axis=1)\n",
    "                correct_class = tf.round(tf.tanh(summed_hot))\n",
    "                \"\"\"\n",
    "                number_in_set = tf.constant([set_size])\n",
    "                divide = tf.cast(tf.tile(number_in_set, [n_final_layer]), tf.float32)\n",
    "                correct_class = tf.divide(summed_hot, divide)\n",
    "                \"\"\"\n",
    "                \n",
    "                #loss_cat = tf.losses.softmax_cross_entropy(correct_class,softmax)\n",
    "                #loss_cat = tf.losses.mean_squared_error(correct_class, softmax)\n",
    "                loss_cat = tf.losses.sigmoid_cross_entropy(multi_class_labels=correct_class, logits=logits)   \n",
    "                loss_summary_cat = tf.summary.scalar('loss_summary_cat', loss_cat)\n",
    "                \n",
    "        with tf.name_scope(\"eval_cat\"):\n",
    "            class_closeness = classes_guess - correct_class\n",
    "            batch_clossness = tf.expand_dims(tf.reduce_sum(tf.abs(class_closeness), axis=1),1)\n",
    "            perfect = tf.broadcast_to(tf.constant([1.00]),[tf.shape(classes_guess)[0],1]) \n",
    "            class_accuracy = tf.reduce_mean(perfect - tf.nn.tanh(tf.nn.relu(batch_clossness)), name='Class_Accuracy')\n",
    "            accuracy_summary_class = tf.summary.scalar('accuracy_summary_class', class_accuracy)\n",
    "            \n",
    "        with tf.name_scope(\"train\"):\n",
    "            global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_class)\n",
    "\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            deep_train = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "            with tf.control_dependencies(extra_update_ops):\n",
    "                with tf.control_dependencies(deep_train):\n",
    "                    training_op_class = optimizer.minimize(loss_cat, global_step=global_step)\n",
    "                \n",
    "    with tf.name_scope('Unique_Identify'):\n",
    "        n_unq_1 = 100\n",
    "        n_unq_2 = 10\n",
    "        n_unq_final = 2\n",
    "        \n",
    "        with tf.name_scope('DeepSet_Unq_Layer_1'):\n",
    "            #500 Output\n",
    "            deep_unq_1 = deep_set_layer(deep_1, n_layer_1, n_layer_2, set_size=3, layer_name='Deep_Unq_One', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('DeepSet_Unq_Layer_2'):\n",
    "            #250 Output\n",
    "            deep_unq_2 = deep_set_layer(deep_unq_1, n_layer_2, n_layer_3, set_size=3, layer_name='Deep_Unq_Two', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('Final_Unq_Deep_Pool'):\n",
    "            #250 Output\n",
    "            final_unq_deep_layer = tf.reduce_sum(deep_unq_2, 1)\n",
    "            \n",
    "        with tf.name_scope(\"Unq_Hidden_Layer_1\"):\n",
    "            #100 Output\n",
    "            hidden1_unq = tf.layers.dense(final_unq_deep_layer, n_unq_1, name=\"hidden1_unq\", kernel_initializer=he_init)\n",
    "            hidden1_drop_unq = tf.layers.dropout(hidden1_unq, dropout_rate, training=training)\n",
    "            hidden1_cast_unq = tf.cast(hidden1_drop_unq, tf.float32)\n",
    "            bn1_cat_unq = bn_batch_norm_layer(hidden1_cast_unq)\n",
    "            bn1_act_cat_unq = tf.nn.relu(bn1_cat_unq)  \n",
    "            \n",
    "        with tf.name_scope(\"Unq_Hidden_Layer_2\"):\n",
    "            #10 Output\n",
    "            hidden2_unq = tf.layers.dense(bn1_act_cat_unq, n_unq_2, name=\"hidden2_unq\", kernel_initializer=he_init)\n",
    "            hidden2_drop_unq = tf.layers.dropout(hidden2_unq, dropout_rate, training=training)\n",
    "            bn2_cat_unq = bn_batch_norm_layer(hidden2_drop_unq)\n",
    "            bn2_act_cat_unq = tf.nn.relu(bn2_cat_unq)  \n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"Final_Layer_unq\"): \n",
    "            #Get softmax\n",
    "            logits_before_bn_unq = tf.layers.dense(bn1_act_cat, n_unq_final, name=\"outputs_unq\")\n",
    "            logits_unq = bn_batch_norm_layer(logits_before_bn_unq, name=\"logits_unq\")\n",
    "            softmax_unq = tf.nn.softmax(logits_unq, name=\"final_soft_max_unq\")\n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"Unique_loss\"):\n",
    "            #0 class is different, 1 is the same\n",
    "            select = tf.not_equal(uniques, tf.constant([1], dtype=tf.int32))\n",
    "            zeros = tf.zeros_like(uniques, dtype=tf.int32)\n",
    "            ones = tf.ones_like(uniques, dtype=tf.int32)\n",
    "            labels = tf.squeeze(tf.where(select, zeros, ones), name='Unq_Labels')\n",
    "            \n",
    "            \n",
    "            #Get cross entropy from labels\n",
    "            xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits_unq)\n",
    "            loss_unq = tf.reduce_mean(xentropy, name=\"loss_unq\")\n",
    "            loss_summary_unq = tf.summary.scalar('loss_summary_unq', loss_unq)\n",
    "            \n",
    "        with tf.name_scope(\"eval_unq\"):\n",
    "            correct = tf.nn.in_top_k(logits_unq, labels, 1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "            accuracy_summary = tf.summary.scalar('accuracy_summary', accuracy)\n",
    "                \n",
    "        with tf.name_scope(\"unique_train\"):\n",
    "            global_step_unique = tf.Variable(0, trainable=False, name='global_step_unique')\n",
    "            optimizer_unq = tf.train.AdamOptimizer(learning_rate=learning_rate_class)\n",
    "\n",
    "            extra_update_ops_unq = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(extra_update_ops_unq):\n",
    "                with tf.control_dependencies(deep_train):\n",
    "                    training_op_unq = optimizer_unq.minimize(loss_unq, global_step=global_step_unique)\n",
    "            \n",
    "\n",
    "init = tf.global_variables_initializer()    \n",
    "saver_total = tf.train.Saver(name=\"Full_Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Graph to log directory\n",
    "#filewriter = tf.summary.FileWriter(model_path, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the network\n",
    "\"\"\"\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver_total.save(sess, set_net_model)\n",
    "    saver_total.save(sess, set_net_model_best)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/AI/models/set_project/model/set_project\n"
     ]
    }
   ],
   "source": [
    "batch = 30\n",
    "epochs = 1\n",
    "with tf.Session() as sess:\n",
    "    #init.run()\n",
    "    #initialize iterator\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    sess.run(train_iterator.initializer, feed_dict={filename: train_list, batch_size: batch, num_epochs:epochs})\n",
    "    train_handle = sess.run(train_iterator.string_handle())\n",
    "    \n",
    "    p,b = sess.run([perfect, class_accuracy], feed_dict={handle: train_handle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network\n",
    "\n",
    "Train the network to both generate conditioning for the network and also classify the type of set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "steps_between_test_save = 1\n",
    "batch = 30\n",
    "train_size = 64000\n",
    "#all_data_steps = np.int(np.floor(train_size/batch))\n",
    "all_data_steps = 100\n",
    "lowest_loss = 10000\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    #restore saver, build iterator, set the step to the global step\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    \n",
    "    #Set up the global steps\n",
    "    step = 1\n",
    "    print(\"Loaded model. Training network initially. Logs into: \" + model_path)\n",
    "    \n",
    "    #initialize iterator\n",
    "    sess.run(train_iterator.initializer, feed_dict={filename: train_list, batch_size: batch, num_epochs:epochs})\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: batch, num_epochs:epochs})\n",
    "    train_handle = sess.run(train_iterator.string_handle())\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "    \n",
    "    #Iterate through training \n",
    "    while step < epochs:\n",
    "        for i in range(all_data_steps):\n",
    "\n",
    "            #run Training Op\n",
    "            sess.run([training_op_class, training_op_unq], feed_dict={handle: train_handle, batch_size: batch})\n",
    "        \n",
    "        #see if we are improving on the test data\n",
    "        #Maybe Test Accuracy\n",
    "        if ((step % steps_between_test_save) == 0) :\n",
    "            loss_sum, loss_val, loss_un, loss_un_val, acc_sum, acc_class = sess.run([loss_summary_cat, loss_cat, loss_summary_unq, loss_unq, accuracy_summary, accuracy_summary_class], \n",
    "                                                   feed_dict = {handle: val_handle ,training: False, batch_size: batch})\n",
    "            filewriter.add_summary(loss_sum, step)\n",
    "            filewriter.add_summary(loss_un, step)\n",
    "            filewriter.add_summary(acc_sum, step)\n",
    "            filewriter.add_summary(acc_class, step)\n",
    "            print(\"Epoch: \" + str(step) + \" Class Loss: \" + str(loss_val) + \" Unique Loss: \" + str(loss_un_val))\n",
    "            if lowest_loss > loss_val:\n",
    "                saver_total.save(sess, set_net_model_best)\n",
    "                lowest_loss = loss_val\n",
    "            saver_total.save(sess, set_net_model)\n",
    "        step = step + 1\n",
    "            \n",
    "    #Finish the final Model\n",
    "    saver_total.save(sess, set_net_model)\n",
    "    end_time = time.time()\n",
    "    total_steps = tf.train.global_step(sess, global_step)\n",
    "    final_time = end_time - start_time\n",
    "    print(\"Did \" + str(total_steps) + \" of loss minimized training in \" + str(final_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Training\n",
    "\n",
    "Here we will see how the network performs after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/AI/models/set_project/model/set_project\n"
     ]
    }
   ],
   "source": [
    "batch = 30\n",
    "epochs = 100\n",
    "num_iter = 200\n",
    "with tf.Session() as sess:\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    #initialize iterator\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: batch, num_epochs:epochs})\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "    right, guess, acc, cond, ims, cc = sess.run([correct_class, classes_guess, class_accuracy, conditionals, file_data, code_data], feed_dict={handle: val_handle, training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3365136\n"
     ]
    }
   ],
   "source": [
    "#Get final parameter count\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'ILSVRC2012_val_00041840.JPEG,ILSVRC2012_val_00042357.JPEG,ILSVRC2012_val_00043067.JPEG,'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ims[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "core_code = cc[item_number]\n",
    "for i in core_code:\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(i)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array_Position: 2 Class_Label: Siberian_husky\n",
      "Array_Position: 53 Class_Label: colobus\n",
      "Array_Position: 57 Class_Label: coyote\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_set = np.where(right[item_number] == 1)[0]\n",
    "for i in in_set:\n",
    "    print('Array_Position: ' + str(i)  + ' Class_Label: ' + label_file[i])\n",
    "right[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array_Position: 2 Class_Label: Siberian_husky\n",
      "Array_Position: 53 Class_Label: colobus\n",
      "Array_Position: 57 Class_Label: coyote\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_set = np.where(guess[item_number] == 1)[0]\n",
    "for i in in_set:\n",
    "    print('Array_Position: ' + str(i)  + ' Class_Label: ' + label_file[i])\n",
    "guess[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99992514"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond[item_number][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Demonstration\n",
    "\n",
    "Here we are going to show running the bones of the network and look a the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #Initialize Train and validation iterator\n",
    "    sess.run(train_iterator.initializer, feed_dict={filename: train_list, batch_size: 1, num_epochs:1})\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: 1, num_epochs:1})\n",
    "    train_handle = sess.run(train_iterator.string_handle())\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "\n",
    "    test_code, test_class, test_file, test_unique = sess.run([code, class_data, file_data, uniques], feed_dict={handle: val_handle,training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show codes from single example\n",
    "for i in range(0,3):\n",
    "    X_test = test_code[0][i]\n",
    "    x_val = X_test\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(x_val)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show class for each item in set\n",
    "for i in range(0,3):\n",
    "    X_test = test_class[0][i]\n",
    "    print('Class: ' + str(X_test) + ' Label: ' + labels[X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show what images the codes came from\n",
    "print(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show how many unitque Items are in the set\n",
    "test_unique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
