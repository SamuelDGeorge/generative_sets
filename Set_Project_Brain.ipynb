{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#general\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#for utility packages\n",
    "from Utilities.utilities import import_data\n",
    "from Utilities.utilities import reset_graph\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tan.tan_util import get_tan_nll as tan\n",
    "from tan.tan_util import get_tan_nll_cond as tan_cond\n",
    "\n",
    "from tensorflow.contrib.slim.nets import resnet_v2\n",
    "import imagenet_helper_files.vgg_preprocessing\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "#For parsing records once written\n",
    "from Utilities.set_record_parser import build_set_dataset\n",
    "from Utilities.set_record_parser import get_file_lists\n",
    "from Utilities.models import log_dir_build\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Directories \n",
    "\n",
    "Here we are going to get the files needed to do the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate Neccesary Files\n",
    "homogenous_train = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Original_Images_Train.pkl\", \"rb\")\n",
    "nonhomogenous_train = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Inhomogeneous_Images_Train.pkl\", \"rb\")\n",
    "homogenous_test = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Original_Images_Test.pkl\", \"rb\")\n",
    "nonhomogenous_test = open(\"D:/Machine_Learning/Datasets/cortical_images/L/Inhomogeneous_Images_Test.pkl\", \"rb\")\n",
    "train_homog = pickle.load(homogenous_train)\n",
    "train_homog_labels = np.zeros(train_homog.shape[0])\n",
    "train_nonhomog = pickle.load(nonhomogenous_train)\n",
    "train_nonhomog_labels = np.ones(train_homog.shape[0])\n",
    "test_homog = pickle.load(homogenous_test)\n",
    "test_homog_labels = np.zeros(test_homog.shape[0])\n",
    "test_nonhomog = pickle.load(nonhomogenous_test)\n",
    "test_nonhomog_labels = np.ones(test_homog.shape[0])\n",
    "homogenous_train.close()\n",
    "nonhomogenous_train.close()\n",
    "homogenous_test.close()\n",
    "nonhomogenous_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine into full train and test set as well as ground truth\n",
    "full_train = np.expand_dims(np.concatenate((train_homog, train_nonhomog), axis = 0), axis=4)\n",
    "full_train_labels = np.concatenate((train_homog_labels, train_nonhomog_labels), axis=0)\n",
    "\n",
    "full_test = np.expand_dims(np.concatenate((test_homog, test_nonhomog), axis = 0), axis=4)\n",
    "full_test_labels = np.concatenate((test_homog_labels, test_nonhomog_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_1 = full_test[0]\n",
    "full_test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Neural Network\n",
    "\n",
    "The following provides the code to import and use the TF_Records for the set project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory for logs in training\n",
    "set_net_logs = 'D:/AI/models/set_project_brain/logs'\n",
    "model_path = log_dir_build(set_net_logs, \"set_project_brain\")\n",
    "#model_path = 'D:/AI/models/set_project_brain/logs/set_project-run-20190306174848/'\n",
    "\n",
    "#directory for all the models saved during training\n",
    "set_net_model = 'D:/AI/models/set_project_brain/model/' + 'set_project'\n",
    "set_net_model_best = 'D:/AI/models/set_project_brain/model/' + 'set_project_best'\n",
    "res_net_model = \"D:/AI/models/res_net/v2_50/resnet_v2_50.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_set_layer(input_code, input_size, condense_size, set_size=3, layer_name='default', activation_func=tf.nn.sigmoid):\n",
    "    \n",
    "    learned_transform = tf.get_variable(layer_name + '_transform', shape=[input_size,condense_size], \n",
    "                                        trainable=True, initializer=tf.contrib.layers.variance_scaling_initializer()) \n",
    "    batched_transform = tf.broadcast_to(learned_transform, [tf.shape(input_code)[0], input_size, condense_size])\n",
    "    transform_layer = tf.matmul(input_code, batched_transform)\n",
    "    activation = activation_func(transform_layer)\n",
    "    \n",
    "    \n",
    "    lambda_1 = tf.get_variable(layer_name + \"_lambda\", [condense_size], trainable=True, dtype=tf.float32, initializer=tf.initializers.random_normal(mean=1))\n",
    "    lambda_1_transformed = tf.broadcast_to(lambda_1, [set_size, condense_size])\n",
    "    multipy_pairwise = tf.broadcast_to(lambda_1_transformed, [tf.shape(input_code)[0], set_size, condense_size])\n",
    "    \n",
    "    sigma_1 = tf.abs(tf.get_variable(layer_name + \"_sigma\", [condense_size], trainable=True, dtype=tf.float32, initializer=tf.initializers.random_normal(mean=0)))\n",
    "    sigma_1_tranformed = tf.broadcast_to(sigma_1, [tf.shape(input_code)[0], condense_size])\n",
    "    \n",
    "\n",
    "    # + sigma * mean(Data)\n",
    "    max_pool_1 = tf.reduce_mean(activation, axis=1)\n",
    "    sum_term = tf.multiply(sigma_1_tranformed, max_pool_1)\n",
    "    sum_term_final = tf.expand_dims(sum_term, axis=1)  \n",
    "    \n",
    "    pre_activation_1 = tf.multiply(activation, multipy_pairwise) + sum_term_final\n",
    "    layer_1 = activation_func(pre_activation_1)\n",
    "    return layer_1\n",
    "\n",
    "def pad_and_input(original_image):\n",
    "    new_image = tf.image.resize_image_with_crop_or_pad(original_image, 331,331)\n",
    "    new_image = tf.image.grayscale_to_rgb(new_image)\n",
    "    return new_image\n",
    "\n",
    "def resnet_build(input):\n",
    "    input = pad_and_input(input)\n",
    "    net, end_points = resnet_v2.resnet_v2_50(input, is_training=False)\n",
    "    saver = tf.train.Saver(name=\"Original_Saver\")\n",
    "    return(net, end_points, saver)\n",
    "\n",
    "def get_resnet_estimate(item):\n",
    "    item = pad_and_input(item)\n",
    "    net, end_points = resnet_v2.resnet_v2_50(item, reuse=True,is_training=False)\n",
    "    net = tf.layers.flatten(net)\n",
    "    return(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"StopGradient:0\", shape=(?, 3, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "#Placeholder for choosing input, epochs, batches, and datasets at runtime\n",
    "learning_rate_class = .01\n",
    "dropout_rate = 0.2\n",
    "set_size = 3\n",
    "    \n",
    "with tf.name_scope('Data_Retrieval'):\n",
    "    #put the data in the graph\n",
    "    batch_size = tf.placeholder_with_default(30, shape=[], name= \"Batch_Size\")\n",
    "    training = tf.placeholder_with_default(True, shape=(), name = 'training')\n",
    "    data_set = tf.placeholder(shape=[None,set_size,128,128,1], name=\"All_Data\", dtype=tf.float32)\n",
    "    image_set = tf.placeholder(shape=[None,set_size,331,331,3], name=\"All_Data\", dtype=tf.float32)\n",
    "    data_label = tf.placeholder(shape=[None], name=\"Data_Labels\", dtype=tf.int32)  \n",
    "    data_sample = tf.placeholder(shape=[set_size,128,128,1], name=\"All_Data_sample\", dtype=tf.float32)\n",
    "    image_sample = tf.placeholder(shape=[set_size,331,331,3], name=\"All_Data_sample\", dtype=tf.float32)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"BN_Layer_AE_Layers\"):\n",
    "    #Define initalizer and batch normalization layers\n",
    "    bn_batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "with slim.arg_scope(resnet_v2.resnet_arg_scope()):\n",
    "    final_net_output, end_point, saver_resnet = resnet_build(data_sample)\n",
    "    encoding_raw = tf.map_fn(lambda x: get_resnet_estimate(x), data_set, dtype=(tf.float32))\n",
    "    encoding = tf.stop_gradient(encoding_raw)\n",
    "print(encoding)\n",
    "\n",
    "with tf.name_scope(\"Set_Analyzer\"):\n",
    "    #the network for generating output of our set\n",
    "    with tf.name_scope('Unique_Identify'):\n",
    "        code_size = 2048\n",
    "        n_layer_1 = 1000\n",
    "        n_layer_2 = 500\n",
    "        n_layer_3 = 250\n",
    "        n_unq_1 = 100\n",
    "        n_unq_2 = 10\n",
    "        n_unq_final = 2\n",
    "        deep_activation = tf.nn.relu\n",
    "        \n",
    "        batch_item = batch_size\n",
    "        \n",
    "        with tf.name_scope('DeepSet_Layer_1'):\n",
    "            #1000\n",
    "            deep_1 = deep_set_layer(encoding, code_size, n_layer_1, set_size=3, layer_name='Deep_One', activation_func=deep_activation)\n",
    "        \n",
    "        with tf.name_scope('DeepSet_Unq_Layer_1'):\n",
    "            #500 Output\n",
    "            deep_unq_1 = deep_set_layer(deep_1, n_layer_1, n_layer_2, set_size=3, layer_name='Deep_Unq_One', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('DeepSet_Unq_Layer_2'):\n",
    "            #250 Output\n",
    "            deep_unq_2 = deep_set_layer(deep_unq_1, n_layer_2, n_layer_3, set_size=3, layer_name='Deep_Unq_Two', activation_func=deep_activation)\n",
    "            \n",
    "        with tf.name_scope('Final_Unq_Deep_Pool'):\n",
    "            #250 Output\n",
    "            final_unq_deep_layer = tf.reduce_sum(deep_unq_2, 1)\n",
    "            \n",
    "        with tf.name_scope(\"Unq_Hidden_Layer_1\"):\n",
    "            #100 Output\n",
    "            hidden1_unq = tf.layers.dense(final_unq_deep_layer, n_unq_1, name=\"hidden1_unq\", kernel_initializer=he_init)\n",
    "            hidden1_drop_unq = tf.layers.dropout(hidden1_unq, dropout_rate, training=training)\n",
    "            hidden1_cast_unq = tf.cast(hidden1_drop_unq, tf.float32)\n",
    "            bn1_cat_unq = bn_batch_norm_layer(hidden1_cast_unq)\n",
    "            bn1_act_cat_unq = tf.nn.relu(bn1_cat_unq)  \n",
    "            \n",
    "        with tf.name_scope(\"Unq_Hidden_Layer_2\"):\n",
    "            #10 Output\n",
    "            hidden2_unq = tf.layers.dense(bn1_act_cat_unq, n_unq_2, name=\"hidden2_unq\", kernel_initializer=he_init)\n",
    "            hidden2_drop_unq = tf.layers.dropout(hidden2_unq, dropout_rate, training=training)\n",
    "            bn2_cat_unq = bn_batch_norm_layer(hidden2_drop_unq)\n",
    "            bn2_act_cat_unq = tf.nn.relu(bn2_cat_unq)  \n",
    "        \n",
    "        \n",
    "        with tf.name_scope(\"Final_Layer_unq\"): \n",
    "            #Get softmax\n",
    "            logits_before_bn_unq = tf.layers.dense(bn2_act_cat_unq, n_unq_final, name=\"outputs_unq\")\n",
    "            logits_unq = bn_batch_norm_layer(logits_before_bn_unq, name=\"logits_unq\")\n",
    "            softmax_unq = tf.nn.softmax(logits_unq, name=\"final_soft_max_unq\")\n",
    "            \n",
    "            \n",
    "        with tf.name_scope(\"Unique_loss\"):           \n",
    "            \n",
    "            #Get cross entropy from labels\n",
    "            xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=data_label, logits=logits_unq)\n",
    "            loss_unq = tf.reduce_mean(xentropy, name=\"loss_unq\")\n",
    "            loss_summary_unq = tf.summary.scalar('loss_summary_unq', loss_unq)\n",
    "            \n",
    "        with tf.name_scope(\"eval_unq\"):\n",
    "            correct = tf.nn.in_top_k(logits_unq, data_label, 1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "            accuracy_summary = tf.summary.scalar('accuracy_summary', accuracy)\n",
    "                \n",
    "        with tf.name_scope(\"unique_train\"):\n",
    "            global_step_unique = tf.Variable(0, trainable=False, name='global_step_unique')\n",
    "            optimizer_unq = tf.train.AdamOptimizer(learning_rate=learning_rate_class)\n",
    "\n",
    "            extra_update_ops_unq = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "            with tf.control_dependencies(extra_update_ops_unq):\n",
    "                 training_op_unq = optimizer_unq.minimize(loss_unq, global_step=global_step_unique)\n",
    "\n",
    "init = tf.global_variables_initializer()    \n",
    "saver_total = tf.train.Saver(name=\"Full_Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Graph to log directory\n",
    "filewriter = tf.summary.FileWriter(model_path, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26222216\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/AI/models/res_net/v2_50/resnet_v2_50.ckpt\n"
     ]
    }
   ],
   "source": [
    "#Initialize the network\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver_resnet.restore(sess,res_net_model)\n",
    "    saver_total.save(sess, set_net_model)\n",
    "    saver_total.save(sess, set_net_model_best)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/AI/models/set_project_brain/logs/set_project_brain-run-20190421200123/\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network\n",
    "\n",
    "Train the network to both generate conditioning for the network and also classify the type of set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/AI/models/set_project_brain/model/set_project\n",
      "Loaded model. Training network initially. Logs into: D:/AI/models/set_project_brain/logs/set_project_brain-run-20190421200123/\n",
      "Epoch: 1 Unique Loss: 8.830122 Accuracy: 0.33333334\n",
      "Epoch: 2 Unique Loss: 48.345074 Accuracy: 0.53333336\n",
      "Epoch: 3 Unique Loss: 4.2135034 Accuracy: 0.6666667\n",
      "Epoch: 4 Unique Loss: 4.4252152 Accuracy: 0.53333336\n",
      "Epoch: 5 Unique Loss: 2.7327025 Accuracy: 0.73333335\n",
      "Epoch: 6 Unique Loss: 1.367785 Accuracy: 0.73333335\n",
      "Epoch: 7 Unique Loss: 1.5365306 Accuracy: 0.6\n",
      "Epoch: 8 Unique Loss: 1.805729 Accuracy: 0.33333334\n",
      "Epoch: 9 Unique Loss: 1.1966574 Accuracy: 0.46666667\n",
      "Epoch: 10 Unique Loss: 1.1794622 Accuracy: 0.33333334\n",
      "Epoch: 11 Unique Loss: 0.63341635 Accuracy: 0.6666667\n",
      "Epoch: 12 Unique Loss: 0.74161476 Accuracy: 0.46666667\n",
      "Epoch: 13 Unique Loss: 0.7159379 Accuracy: 0.53333336\n",
      "Epoch: 14 Unique Loss: 0.6882683 Accuracy: 0.6\n",
      "Epoch: 15 Unique Loss: 0.78807575 Accuracy: 0.46666667\n",
      "Epoch: 16 Unique Loss: 0.90890336 Accuracy: 0.26666668\n",
      "Epoch: 17 Unique Loss: 0.6771334 Accuracy: 0.6\n",
      "Epoch: 18 Unique Loss: 0.748792 Accuracy: 0.46666667\n",
      "Epoch: 19 Unique Loss: 0.67893904 Accuracy: 0.6\n",
      "Epoch: 20 Unique Loss: 0.5565497 Accuracy: 0.8\n",
      "Epoch: 21 Unique Loss: 0.7489596 Accuracy: 0.46666667\n",
      "Epoch: 22 Unique Loss: 0.8100698 Accuracy: 0.33333334\n",
      "Epoch: 23 Unique Loss: 0.8011884 Accuracy: 0.33333334\n",
      "Epoch: 24 Unique Loss: 0.76249766 Accuracy: 0.4\n",
      "Epoch: 25 Unique Loss: 0.70743674 Accuracy: 0.46666667\n",
      "Epoch: 26 Unique Loss: 0.7145462 Accuracy: 0.46666667\n",
      "Epoch: 27 Unique Loss: 0.69060314 Accuracy: 0.53333336\n",
      "Epoch: 28 Unique Loss: 0.69538003 Accuracy: 0.53333336\n",
      "Epoch: 29 Unique Loss: 0.697723 Accuracy: 0.46666667\n",
      "Epoch: 30 Unique Loss: 0.64617896 Accuracy: 0.8\n",
      "Epoch: 31 Unique Loss: 0.68936753 Accuracy: 0.53333336\n",
      "Epoch: 32 Unique Loss: 0.6916316 Accuracy: 0.53333336\n",
      "Epoch: 33 Unique Loss: 0.6885929 Accuracy: 0.53333336\n",
      "Epoch: 34 Unique Loss: 0.67927235 Accuracy: 0.6\n",
      "Epoch: 35 Unique Loss: 0.663998 Accuracy: 0.6666667\n",
      "Epoch: 36 Unique Loss: 0.6919973 Accuracy: 0.53333336\n",
      "Epoch: 37 Unique Loss: 0.7309705 Accuracy: 0.4\n",
      "Epoch: 38 Unique Loss: 0.6493113 Accuracy: 0.6666667\n",
      "Epoch: 39 Unique Loss: 0.71722317 Accuracy: 0.46666667\n",
      "Epoch: 40 Unique Loss: 0.7352158 Accuracy: 0.4\n",
      "Epoch: 41 Unique Loss: 0.76559484 Accuracy: 0.26666668\n",
      "Epoch: 42 Unique Loss: 0.67909724 Accuracy: 0.6\n",
      "Epoch: 43 Unique Loss: 0.73223764 Accuracy: 0.33333334\n",
      "Epoch: 44 Unique Loss: 0.67951745 Accuracy: 0.6\n",
      "Epoch: 45 Unique Loss: 0.6817478 Accuracy: 0.6\n",
      "Epoch: 46 Unique Loss: 0.7004233 Accuracy: 0.46666667\n",
      "Epoch: 47 Unique Loss: 0.66724557 Accuracy: 0.73333335\n",
      "Epoch: 48 Unique Loss: 0.7133322 Accuracy: 0.33333334\n",
      "Epoch: 49 Unique Loss: 0.7087878 Accuracy: 0.4\n",
      "Epoch: 50 Unique Loss: 0.7126184 Accuracy: 0.33333334\n",
      "Epoch: 51 Unique Loss: 0.7069847 Accuracy: 0.4\n",
      "Epoch: 52 Unique Loss: 0.69326365 Accuracy: 0.46666667\n",
      "Epoch: 53 Unique Loss: 0.7017239 Accuracy: 0.4\n",
      "Epoch: 54 Unique Loss: 0.69035184 Accuracy: 0.53333336\n",
      "Epoch: 55 Unique Loss: 0.70175624 Accuracy: 0.33333334\n",
      "Epoch: 56 Unique Loss: 0.6948022 Accuracy: 0.4\n",
      "Epoch: 57 Unique Loss: 0.6933464 Accuracy: 0.33333334\n",
      "Epoch: 58 Unique Loss: 0.69235396 Accuracy: 0.6\n",
      "Epoch: 59 Unique Loss: 0.6911738 Accuracy: 0.6\n",
      "Epoch: 60 Unique Loss: 0.69518244 Accuracy: 0.46666667\n",
      "Epoch: 61 Unique Loss: 0.6852492 Accuracy: 0.6666667\n",
      "Epoch: 62 Unique Loss: 0.6948175 Accuracy: 0.46666667\n",
      "Epoch: 63 Unique Loss: 0.6985126 Accuracy: 0.4\n",
      "Epoch: 64 Unique Loss: 0.6914985 Accuracy: 0.53333336\n",
      "Epoch: 65 Unique Loss: 0.6797941 Accuracy: 0.8666667\n",
      "Epoch: 66 Unique Loss: 0.6915895 Accuracy: 0.6\n",
      "Epoch: 67 Unique Loss: 0.69238126 Accuracy: 0.53333336\n",
      "Epoch: 68 Unique Loss: 0.6936081 Accuracy: 0.46666667\n",
      "Epoch: 69 Unique Loss: 0.6931379 Accuracy: 0.53333336\n",
      "Epoch: 70 Unique Loss: 0.69545007 Accuracy: 0.33333334\n",
      "Epoch: 71 Unique Loss: 0.6954514 Accuracy: 0.46666667\n",
      "Epoch: 72 Unique Loss: 0.69881177 Accuracy: 0.4\n",
      "Epoch: 73 Unique Loss: 0.678042 Accuracy: 0.8\n",
      "Epoch: 74 Unique Loss: 0.700663 Accuracy: 0.4\n",
      "Epoch: 75 Unique Loss: 0.6805007 Accuracy: 0.73333335\n",
      "Epoch: 76 Unique Loss: 0.6917011 Accuracy: 0.53333336\n",
      "Epoch: 77 Unique Loss: 0.7003091 Accuracy: 0.4\n",
      "Epoch: 78 Unique Loss: 0.6839015 Accuracy: 0.6\n",
      "Epoch: 79 Unique Loss: 0.68023163 Accuracy: 0.6\n",
      "Epoch: 80 Unique Loss: 0.6906341 Accuracy: 0.53333336\n",
      "Epoch: 81 Unique Loss: 0.6902757 Accuracy: 0.53333336\n",
      "Epoch: 82 Unique Loss: 0.70068103 Accuracy: 0.46666667\n",
      "Epoch: 83 Unique Loss: 0.66795677 Accuracy: 0.6666667\n",
      "Epoch: 84 Unique Loss: 0.6913912 Accuracy: 0.53333336\n",
      "Epoch: 85 Unique Loss: 0.7224726 Accuracy: 0.4\n",
      "Epoch: 86 Unique Loss: 0.7045656 Accuracy: 0.46666667\n",
      "Epoch: 87 Unique Loss: 0.66785705 Accuracy: 0.6666667\n",
      "Epoch: 88 Unique Loss: 0.69091314 Accuracy: 0.53333336\n",
      "Epoch: 89 Unique Loss: 0.70320755 Accuracy: 0.46666667\n",
      "Epoch: 90 Unique Loss: 0.66226315 Accuracy: 0.73333335\n",
      "Epoch: 91 Unique Loss: 0.69132704 Accuracy: 0.53333336\n",
      "Epoch: 92 Unique Loss: 0.684684 Accuracy: 0.6\n",
      "Epoch: 93 Unique Loss: 0.6869953 Accuracy: 0.6\n",
      "Epoch: 94 Unique Loss: 0.6921858 Accuracy: 0.53333336\n",
      "Epoch: 95 Unique Loss: 0.7035211 Accuracy: 0.4\n",
      "Epoch: 96 Unique Loss: 0.6982403 Accuracy: 0.46666667\n",
      "Epoch: 97 Unique Loss: 0.7080317 Accuracy: 0.4\n",
      "Epoch: 98 Unique Loss: 0.689701 Accuracy: 0.53333336\n",
      "Epoch: 99 Unique Loss: 0.682563 Accuracy: 0.6\n",
      "Epoch: 100 Unique Loss: 0.69921213 Accuracy: 0.46666667\n",
      "Epoch: 101 Unique Loss: 0.68210065 Accuracy: 0.6\n",
      "Epoch: 102 Unique Loss: 0.69841206 Accuracy: 0.46666667\n",
      "Epoch: 103 Unique Loss: 0.6910636 Accuracy: 0.53333336\n",
      "Epoch: 104 Unique Loss: 0.70270246 Accuracy: 0.4\n",
      "Epoch: 105 Unique Loss: 0.6878111 Accuracy: 0.6\n",
      "Epoch: 106 Unique Loss: 0.69461125 Accuracy: 0.46666667\n",
      "Epoch: 107 Unique Loss: 0.6902322 Accuracy: 0.6\n",
      "Epoch: 108 Unique Loss: 0.6915745 Accuracy: 0.6\n",
      "Epoch: 109 Unique Loss: 0.6951696 Accuracy: 0.33333334\n",
      "Epoch: 110 Unique Loss: 0.69533515 Accuracy: 0.4\n",
      "Epoch: 111 Unique Loss: 0.69395614 Accuracy: 0.4\n",
      "Epoch: 112 Unique Loss: 0.69219893 Accuracy: 0.73333335\n",
      "Epoch: 113 Unique Loss: 0.6925536 Accuracy: 0.6\n",
      "Epoch: 114 Unique Loss: 0.6972369 Accuracy: 0.33333334\n",
      "Epoch: 115 Unique Loss: 0.6907713 Accuracy: 0.6\n",
      "Epoch: 116 Unique Loss: 0.6978739 Accuracy: 0.33333334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b2d68ad66557>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0msaver_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_net_model_best\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mworst_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0msaver_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_net_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1464\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m           self.export_meta_graph(\n\u001b[1;32m-> 1466\u001b[1;33m               meta_graph_filename, strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[0;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m         \u001b[0mclear_devices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m         strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[1;34m(filename, meta_info_def, graph_def, saver_def, collection_list, as_text, graph, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, **kwargs)\u001b[0m\n\u001b[0;32m   1798\u001b[0m       \u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_extraneous_savers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m       \u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrip_default_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1800\u001b[1;33m       **kwargs)\n\u001b[0m\u001b[0;32m   1801\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mexport_scoped_meta_graph\u001b[1;34m(filename, graph_def, graph, export_scope, as_text, unbound_inputs_col_name, clear_devices, saver_def, clear_extraneous_savers, strip_default_attrs, **kwargs)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m         as_text=as_text)\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mscoped_meta_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\graph_io.py\u001b[0m in \u001b[0;36mwrite_graph\u001b[1;34m(graph_or_graph_def, logdir, name, as_text)\u001b[0m\n\u001b[0;32m     71\u001b[0m                                         text_format.MessageToString(graph_def))\n\u001b[0;32m     72\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matomic_write_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sdgeo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36matomic_write_string_to_file\u001b[1;34m(filename, contents, overwrite)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0matomic_write_string_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m   \"\"\"Writes to `filename` atomically.\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "steps_between_test_save = 1\n",
    "batch = 15\n",
    "train_size = 600\n",
    "#all_data_steps = np.int(np.floor(train_size/batch))\n",
    "all_data_steps = 2\n",
    "worst_acc = 0\n",
    "\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    #restore saver, build iterator, set the step to the global step\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    \n",
    "    #Set up the global steps\n",
    "    step = 1\n",
    "    print(\"Loaded model. Training network initially. Logs into: \" + model_path)\n",
    "    \n",
    "    #Iterate through training \n",
    "    while step < epochs:\n",
    "        for i in range(all_data_steps):\n",
    "            idx = np.random.randint(full_train.shape[0], size=batch)\n",
    "            batch_train = full_train[idx,:]\n",
    "            batch_train_label = full_train_labels[idx]\n",
    "            \n",
    "            #run Training Op\n",
    "            sess.run([training_op_unq], feed_dict={data_set: batch_train, data_label: batch_train_label})\n",
    "        \n",
    "        #see if we are improving on the test data\n",
    "        #Maybe Test Accuracy\n",
    "        if ((step % steps_between_test_save) == 0) :\n",
    "            idx = np.random.randint(full_test.shape[0], size=batch)\n",
    "            batch_test = full_test[idx,:]\n",
    "            batch_test_label = full_test_labels[idx]\n",
    "            \n",
    "            loss_un, loss_un_val, acc, acc_sum = sess.run([loss_summary_unq, loss_unq, accuracy, accuracy_summary], \n",
    "                                                   feed_dict = {data_set: batch_test , data_label: batch_test_label, training: False, batch_size: batch})\n",
    "\n",
    "            filewriter.add_summary(loss_un, step)\n",
    "            filewriter.add_summary(acc_sum, step)\n",
    "            print(\"Epoch: \" + str(step) + \" Unique Loss: \" + str(loss_un_val) + \" Accuracy: \" + str(acc))\n",
    "            if acc > worst_acc:\n",
    "                saver_total.save(sess, set_net_model_best)\n",
    "                worst_acc = acc\n",
    "            saver_total.save(sess, set_net_model)\n",
    "        step = step + 1\n",
    "            \n",
    "    #Finish the final Model\n",
    "    saver_total.save(sess, set_net_model)\n",
    "    end_time = time.time()\n",
    "    total_steps = tf.train.global_step(sess, global_step_unique)\n",
    "    final_time = end_time - start_time\n",
    "    print(\"Did \" + str(total_steps) + \" of loss minimized training in \" + str(final_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Training\n",
    "\n",
    "Here we will see how the network performs after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 30\n",
    "epochs = 100\n",
    "num_iter = 200\n",
    "with tf.Session() as sess:\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    #initialize iterator\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: batch, num_epochs:epochs})\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "    right, guess, acc, cond, ims, cc = sess.run([correct_class, classes_guess, class_accuracy, conditionals, file_data, code_data], feed_dict={handle: val_handle, training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get final parameter count\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_number = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_code = cc[item_number]\n",
    "for i in core_code:\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(i)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_set = np.where(right[item_number] == 1)[0]\n",
    "for i in in_set:\n",
    "    print('Array_Position: ' + str(i)  + ' Class_Label: ' + label_file[i])\n",
    "right[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_set = np.where(guess[item_number] == 1)[0]\n",
    "for i in in_set:\n",
    "    print('Array_Position: ' + str(i)  + ' Class_Label: ' + label_file[i])\n",
    "guess[item_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond[item_number][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training Metrics\n",
    "\n",
    "Here we will get final accuracies for both tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "steps_between_test_save = 1\n",
    "batch = 30\n",
    "test_size = 26000\n",
    "all_data_steps = np.int(np.floor(test_size/batch))\n",
    "unique_accuracy = 0\n",
    "identify_accuracy = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    start_time = time.time()\n",
    "    #restore saver, build iterator, set the step to the global step\n",
    "    saver_total.restore(sess, set_net_model)\n",
    "    \n",
    "    print(\"Loaded model. Training network initially. Logs into: \" + model_path)\n",
    "    \n",
    "    #initialize iterator\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: batch, num_epochs:epochs})\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "    \n",
    "    for i in range(all_data_steps):\n",
    "        unq_acc, ide_acc = sess.run([accuracy, class_accuracy], feed_dict = {handle: val_handle, training: False})\n",
    "        unique_accuracy = ((i  * unique_accuracy) + unq_acc)/(i + 1)\n",
    "        identify_accuracy = ((i  * identify_accuracy) + ide_acc)/(i + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Demonstration\n",
    "\n",
    "Here we are going to show running the bones of the network and look a the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #Initialize Train and validation iterator\n",
    "    sess.run(train_iterator.initializer, feed_dict={filename: train_list, batch_size: 1, num_epochs:1})\n",
    "    sess.run(val_iterator.initializer, feed_dict={filename: val_list, batch_size: 1, num_epochs:1})\n",
    "    train_handle = sess.run(train_iterator.string_handle())\n",
    "    val_handle = sess.run(val_iterator.string_handle())\n",
    "\n",
    "    test_code, test_class, test_file, test_unique = sess.run([code, class_data, file_data, uniques], feed_dict={handle: val_handle,training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show codes from single example\n",
    "for i in range(0,3):\n",
    "    X_test = test_code[0][i]\n",
    "    x_val = X_test\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.plot(x_val)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show class for each item in set\n",
    "for i in range(0,3):\n",
    "    X_test = test_class[0][i]\n",
    "    print('Class: ' + str(X_test) + ' Label: ' + labels[X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show what images the codes came from\n",
    "print(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show how many unitque Items are in the set\n",
    "test_unique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
